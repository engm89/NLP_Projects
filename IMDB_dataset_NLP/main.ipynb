{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB movie reviews sentiment classifier using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 500\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('IMDB Dataset.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = reviews['review']\n",
    "labels = reviews['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\musta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "filtered_sentences = []\n",
    "for s in sentences:\n",
    "    word_tokens = word_tokenize(s) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentences.append(\" \".join(filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        positive\n",
       "           ...   \n",
       "49995    positive\n",
       "49996    negative\n",
       "49997    negative\n",
       "49998    negative\n",
       "49999    negative\n",
       "Name: sentiment, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(word):\n",
    "    if word == 'positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "labels = labels.apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000,\n",
       " array([[ 28,   5,   2, ...,   0,   0,   0],\n",
       "        [  4, 388, 119, ...,   0,   0,   0],\n",
       "        [ 11, 190,  12, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 10, 811,  21, ...,   0,   0,   0],\n",
       "        [  1, 125,  10, ...,   0,   0,   0],\n",
       "        [ 12,  18,  91, ...,   0,   0,   0]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_sequences),training_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1094/1094 - 7s - loss: 0.4860 - accuracy: 0.7815 - val_loss: 0.3249 - val_accuracy: 0.8649 - 7s/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "1094/1094 - 5s - loss: 0.2631 - accuracy: 0.8989 - val_loss: 0.2937 - val_accuracy: 0.8779 - 5s/epoch - 5ms/step\n",
      "Epoch 3/10\n",
      "1094/1094 - 5s - loss: 0.2177 - accuracy: 0.9177 - val_loss: 0.2968 - val_accuracy: 0.8781 - 5s/epoch - 5ms/step\n",
      "Epoch 4/10\n",
      "1094/1094 - 5s - loss: 0.1922 - accuracy: 0.9273 - val_loss: 0.2610 - val_accuracy: 0.8987 - 5s/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "1094/1094 - 6s - loss: 0.1735 - accuracy: 0.9355 - val_loss: 0.2654 - val_accuracy: 0.8982 - 6s/epoch - 5ms/step\n",
      "Epoch 6/10\n",
      "1094/1094 - 5s - loss: 0.1576 - accuracy: 0.9424 - val_loss: 0.2758 - val_accuracy: 0.8963 - 5s/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "1094/1094 - 5s - loss: 0.1469 - accuracy: 0.9479 - val_loss: 0.2903 - val_accuracy: 0.8922 - 5s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "1094/1094 - 5s - loss: 0.1377 - accuracy: 0.9514 - val_loss: 0.2977 - val_accuracy: 0.8936 - 5s/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "1094/1094 - 5s - loss: 0.1265 - accuracy: 0.9562 - val_loss: 0.3172 - val_accuracy: 0.8907 - 5s/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "1094/1094 - 5s - loss: 0.1189 - accuracy: 0.9600 - val_loss: 0.3288 - val_accuracy: 0.8900 - 5s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence):\n",
    "    sentence = [sentence]\n",
    "    sequences = tokenizer.texts_to_sequences(sentence)\n",
    "    padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    sentiment = model.predict(padded)\n",
    "    return (\"Positive Sentiment\") if sentiment > 0.5 else (\"Negative Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"\"\"The show wants to be a serious mystery. It want's to be grim. There is a constant synth sound in \n",
    "nearly every scene foreshadowing grim things are coming,even on the most banal scenes.It feels like someone in post \n",
    "production wanted to play around with Dolby Atmos as much as possible instead of doing a proper sound mix that supports \n",
    "the action on screen. From a technical aspect the sound is well engineered, but it doesn't do anything for the show.\n",
    "And you get a perfect exercise in overacting by the semi talented cast. Every line is delivered frowned with meaning, \n",
    "swollen as if there were an underlying meaning to every word, glimpse or motion.\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"\"\" It continunes few days after where we left off last season and it focuses more on political drama and dilemmas inside the walls. This season gets straight to the point and introduces new villain named Kenny that turns out to be somehow related to Levi. There are many parties trying to get Eren and Historia. For what reason? It is yet to be reveald. Mystery we all feel in love with is still there and there are even more questions, but don't let that distract you from the fact that this season ,even tho is only few episodes in, already has some major reveals in it. Pacing is amazing and i wasn't bored for a moment while watching. Things are only getting more interesting when Erwin reveals how he's planning to ovethrow the governmant without using the force. This season has a very refreshing and different plot compared to previous ones as we can see from the lack of titans and focuse on the issues inside the walls rather than beyond. However it's still as, if not more interesting than before. There is world buidling,mystery,back stabbing and some major questions answered which there is hopfully more to come.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentence(\"\"\"\n",
    "Another She-Hulk episode, another half an hour wasted.\n",
    "Where to begin? Firstly, its now incredibly clear that this show does not care about getting anywhere anytime soon. Plot may as well not exist in the world of she hulk, since we waste 30 minutes on issues such as dating, weddings and copyright.\n",
    "I can give this episode one positive factor; the acting is mainly good. Of course, the actors cannot save this terrible script, but they mostly try.\n",
    "Another weakness in this episode is the awful CGI and editing. Scenes just clumsily collide with no thought about how they flow. Also, the music is just terrible.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def update(name):\n",
    "    return f\"Welcome to Gradio, {name}!\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"Start typing below and then click **Run** to see the output.\")\n",
    "    with gr.Row():\n",
    "        inp = gr.Textbox(placeholder='Enter a review', label='User Review')\n",
    "        out = gr.Label(label='Sentiment Analysis')\n",
    "    btn = gr.Button(\"Analysis\")\n",
    "    btn.click(fn=predict_sentence, inputs=inp, outputs=out)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
